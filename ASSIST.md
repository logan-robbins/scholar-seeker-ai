# AI Assistant Guide for Scholar Seeker AI

This document provides context, architectural details, and guidelines for AI assistants working on the `scholar-seeker-ai` codebase.

## üß† Project Context
**Scholar Seeker AI** is an autonomous agent that helps arXiv authors find eligible endorsers to sponsor their submissions (e.g., for `cs.AI`). It works by:
1.  Scraping recent papers from a target category.
2.  Authenticating with arXiv (using a persistent session).
3.  Navigating to each paper's abstract page.
4.  Clicking the "Which authors of this paper are endorsers?" link (only visible to logged-in users).
5.  Extracting the list of eligible names.

## üìÇ Architecture

The project is script-based but modular:

- **`scripts/run_endorser_search.py`**: The main orchestrator.
  - Usage: `uv run python scripts/run_endorser_search.py --category cs.AI`
  - Logic: Chains fetching -> auth -> checking -> reporting.
- **`scripts/fetch_papers.py`**: Public scraper.
  - Fetches paper IDs (e.g., `2512.07810`) from `https://arxiv.org/list/CATEGORY/recent`.
- **`scripts/arxiv_endorsement_browser.py`**: The core "Agent".
  - Contains `check_papers_batch` and `check_paper_endorsements`.
  - **Critical**: Uses robust selectors to find the endorsement link (checks `href` and text content).
- **`scripts/arxiv_auth_manager.py`**: Auth Handler.
  - Manages login flow using Playwright.
  - Caches session state to `~/.arxiv_reviewer_cache/arxiv_auth_state.json`.

## üõ†Ô∏è Tooling & Standards

- **Dependency Management**: Use `uv` exclusively.
  - Add packages: `uv add <package>`
  - Run scripts: `uv run python scripts/...`
- **Browser Automation**: `playwright` (async API).
  - Default to `headless=True` for speed, but `headless=False` is supported for debugging/demos.
  - Always use `wait_until="networkidle"` or specific selector waits to handle arXiv's static but sometimes slow loading.
- **Environment**:
  - Secrets (`ARXIV_USER`, `ARXIV_PASS`) are in `.env`.
  - **Never** commit `.env`.

## üöÄ Workflows

### 1. Authentication
The agent checks for a saved session. If missing or expired, it performs a fresh login.
- **AI Task**: If working on auth, verify `verify_auth` in `ArxivAuthManager` correctly detects expiration (redirects to login page).

### 2. Endorsement Extraction
The logic is in `extract_endorsers_from_page`.
- **Strategy**: It scrapes the text of the endorsers page.
- **Improvement Area**: Currently it just gets names. Future work involves parsing institutional data if available.

## üó∫Ô∏è Roadmap / Next Tasks

1.  **Contact Info Discovery**:
    - *Goal*: Find emails for eligible endorsers.
    - *Constraint*: arXiv profile pages do NOT show emails.
    - *Approach*: Implement a search step (e.g., "Satvik Golechha email") or download/parse the PDF (first page usually contains `user@domain.edu`).
2.  **Rate Limiting**:
    - Current: Hardcoded `DEFAULT_DELAY_SECONDS = 30`.
    - *Goal*: Implement adaptive delays or randomized intervals to mimic human behavior better.
3.  **UI/Reporting**:
    - *Goal*: Generate a localized HTML report instead of just JSON/Console output.

## ‚ö†Ô∏è Known Issues
- **Selector Fragility**: The "Which authors..." link text might change. Current fallback is robust but verify if arXiv updates their UI.
- **Captcha**: Heavy usage might trigger Cloudflare/Captcha. We currently rely on persistent sessions to minimize login events, which helps.

---
*Generated by AI for AI - Keep this file updated as the architecture evolves.*

